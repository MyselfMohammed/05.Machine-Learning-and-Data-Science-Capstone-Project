{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb5fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Importing Libraries :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae38080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5242, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crypto</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time - 24 Hour Format</th>\n",
       "      <th>Time - 12 Hour Format</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>Close Minus Open</th>\n",
       "      <th>Adj Close Minus Open</th>\n",
       "      <th>Close Minus Adj Close</th>\n",
       "      <th>High Minus Open</th>\n",
       "      <th>High Minus Close</th>\n",
       "      <th>High Minus Adj Close</th>\n",
       "      <th>High Minus Low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Trade Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-USD</td>\n",
       "      <td>03-10-2020</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>Positive Impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CONX28135-USD</td>\n",
       "      <td>21-03-2025</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>46719.0</td>\n",
       "      <td>17.543959</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180546</td>\n",
       "      <td>0.070890</td>\n",
       "      <td>0.070890</td>\n",
       "      <td>0.242294</td>\n",
       "      <td>17.653614</td>\n",
       "      <td>17.653614</td>\n",
       "      <td>17.724504</td>\n",
       "      <td>17.482210</td>\n",
       "      <td>Positive Impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHX-USD</td>\n",
       "      <td>24-11-2020</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>8190.0</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>Negative Impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PALLA-USD</td>\n",
       "      <td>16-12-2022</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>84921.0</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>Positive Impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PORK29220-USD</td>\n",
       "      <td>16-05-2024</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>12:00 AM</td>\n",
       "      <td>1864946.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>No Impact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Crypto        Date Time - 24 Hour Format Time - 12 Hour Format  \\\n",
       "0        SPC-USD  03-10-2020              00:00:00              12:00 AM   \n",
       "1  CONX28135-USD  21-03-2025              00:00:00              12:00 AM   \n",
       "2        SHX-USD  24-11-2020              00:00:00              12:00 AM   \n",
       "3      PALLA-USD  16-12-2022              00:00:00              12:00 AM   \n",
       "4  PORK29220-USD  16-05-2024              00:00:00              12:00 AM   \n",
       "\n",
       "      volume       open  Close Minus Open  Adj Close Minus Open  \\\n",
       "0     1954.0   0.005614          0.000301              0.000301   \n",
       "1    46719.0  17.543959          0.109655              0.109655   \n",
       "2     8190.0   0.000192         -0.000003             -0.000003   \n",
       "3    84921.0   0.011293          0.000133              0.000133   \n",
       "4  1864946.0   0.000000          0.000000              0.000000   \n",
       "\n",
       "   Close Minus Adj Close  High Minus Open  High Minus Close  \\\n",
       "0                    0.0         0.000305          0.000004   \n",
       "1                    0.0         0.180546          0.070890   \n",
       "2                    0.0         0.000019          0.000022   \n",
       "3                    0.0         0.000147          0.000014   \n",
       "4                    0.0         0.000000          0.000000   \n",
       "\n",
       "   High Minus Adj Close  High Minus Low      close  adj_close       high  \\\n",
       "0              0.000004        0.000390   0.005915   0.005915   0.005919   \n",
       "1              0.070890        0.242294  17.653614  17.653614  17.724504   \n",
       "2              0.000022        0.000032   0.000189   0.000189   0.000211   \n",
       "3              0.000014        0.000162   0.011426   0.011426   0.011440   \n",
       "4              0.000000        0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "         low     Trade Impact  \n",
       "0   0.005529  Positive Impact  \n",
       "1  17.482210  Positive Impact  \n",
       "2   0.000179  Negative Impact  \n",
       "3   0.011278  Positive Impact  \n",
       "4   0.000000        No Impact  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ 1.Loading Original Dataset : \n",
    "dataset=pd.read_csv(\"Preprocessed_Data_Cryptos - One Percent of Actual Dataset.csv\",index_col=None)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bf3629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5242, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>Close Minus Open</th>\n",
       "      <th>Adj Close Minus Open</th>\n",
       "      <th>Close Minus Adj Close</th>\n",
       "      <th>High Minus Open</th>\n",
       "      <th>High Minus Close</th>\n",
       "      <th>High Minus Adj Close</th>\n",
       "      <th>High Minus Low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Trade Impact_No Impact</th>\n",
       "      <th>Trade Impact_Positive Impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1954.0</td>\n",
       "      <td>0.005614</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.005529</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46719.0</td>\n",
       "      <td>17.543959</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.109655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180546</td>\n",
       "      <td>0.070890</td>\n",
       "      <td>0.070890</td>\n",
       "      <td>0.242294</td>\n",
       "      <td>17.653614</td>\n",
       "      <td>17.653614</td>\n",
       "      <td>17.724504</td>\n",
       "      <td>17.482210</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8190.0</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84921.0</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864946.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>211093892.0</td>\n",
       "      <td>375.328049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>375.659451</td>\n",
       "      <td>375.627867</td>\n",
       "      <td>400.833600</td>\n",
       "      <td>365.791182</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>3487036.0</td>\n",
       "      <td>0.073854</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>-0.009214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>0.064640</td>\n",
       "      <td>0.064640</td>\n",
       "      <td>0.078538</td>\n",
       "      <td>0.060769</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5239</th>\n",
       "      <td>6895906.0</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>15719.0</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>0.006267</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>11538948.0</td>\n",
       "      <td>0.374569</td>\n",
       "      <td>-0.033111</td>\n",
       "      <td>-0.033111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.049885</td>\n",
       "      <td>0.341458</td>\n",
       "      <td>0.341458</td>\n",
       "      <td>0.375247</td>\n",
       "      <td>0.325362</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5242 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           volume        open  Close Minus Open  Adj Close Minus Open  \\\n",
       "0          1954.0    0.005614          0.000301              0.000301   \n",
       "1         46719.0   17.543959          0.109655              0.109655   \n",
       "2          8190.0    0.000192         -0.000003             -0.000003   \n",
       "3         84921.0    0.011293          0.000133              0.000133   \n",
       "4       1864946.0    0.000000          0.000000              0.000000   \n",
       "...           ...         ...               ...                   ...   \n",
       "5237  211093892.0  375.328049          0.000000              0.000000   \n",
       "5238    3487036.0    0.073854         -0.009214             -0.009214   \n",
       "5239    6895906.0    0.000381          0.000000              0.000000   \n",
       "5240      15719.0    0.006267          0.000142              0.000142   \n",
       "5241   11538948.0    0.374569         -0.033111             -0.033111   \n",
       "\n",
       "      Close Minus Adj Close  High Minus Open  High Minus Close  \\\n",
       "0                       0.0         0.000305          0.000004   \n",
       "1                       0.0         0.180546          0.070890   \n",
       "2                       0.0         0.000019          0.000022   \n",
       "3                       0.0         0.000147          0.000014   \n",
       "4                       0.0         0.000000          0.000000   \n",
       "...                     ...              ...               ...   \n",
       "5237                    0.0         0.000000          0.000000   \n",
       "5238                    0.0         0.004684          0.013898   \n",
       "5239                    0.0         0.000018          0.000018   \n",
       "5240                    0.0         0.000198          0.000056   \n",
       "5241                    0.0         0.000678          0.033789   \n",
       "\n",
       "      High Minus Adj Close  High Minus Low       close   adj_close  \\\n",
       "0                 0.000004        0.000390    0.005915    0.005915   \n",
       "1                 0.070890        0.242294   17.653614   17.653614   \n",
       "2                 0.000022        0.000032    0.000189    0.000189   \n",
       "3                 0.000014        0.000162    0.011426    0.011426   \n",
       "4                 0.000000        0.000000    0.000000    0.000000   \n",
       "...                    ...             ...         ...         ...   \n",
       "5237              0.000000        0.000000  375.659451  375.627867   \n",
       "5238              0.013898        0.017769    0.064640    0.064640   \n",
       "5239              0.000018        0.000022    0.000381    0.000381   \n",
       "5240              0.000056        0.000198    0.006409    0.006409   \n",
       "5241              0.033789        0.049885    0.341458    0.341458   \n",
       "\n",
       "            high         low  Trade Impact_No Impact  \\\n",
       "0       0.005919    0.005529                   False   \n",
       "1      17.724504   17.482210                   False   \n",
       "2       0.000211    0.000179                   False   \n",
       "3       0.011440    0.011278                   False   \n",
       "4       0.000000    0.000000                    True   \n",
       "...          ...         ...                     ...   \n",
       "5237  400.833600  365.791182                    True   \n",
       "5238    0.078538    0.060769                   False   \n",
       "5239    0.000399    0.000377                    True   \n",
       "5240    0.006465    0.006267                   False   \n",
       "5241    0.375247    0.325362                   False   \n",
       "\n",
       "      Trade Impact_Positive Impact  \n",
       "0                             True  \n",
       "1                             True  \n",
       "2                            False  \n",
       "3                             True  \n",
       "4                            False  \n",
       "...                            ...  \n",
       "5237                         False  \n",
       "5238                         False  \n",
       "5239                         False  \n",
       "5240                          True  \n",
       "5241                         False  \n",
       "\n",
       "[5242 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#✅ 2.Duplicating the Original Dataset\n",
    "dataset2 = dataset.drop(['Crypto','Date','Time - 24 Hour Format','Time - 12 Hour Format'],axis=1)\n",
    "\n",
    "#✅ 3.Classifying the Nominal Columns in Dataset : \n",
    "dataset2 = pd.get_dummies(dataset2, drop_first=True)\n",
    "print(dataset2.shape)\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1457900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['volume', 'open', 'Close Minus Open', 'Adj Close Minus Open',\n",
       "       'Close Minus Adj Close', 'High Minus Open', 'High Minus Close',\n",
       "       'High Minus Adj Close', 'High Minus Low', 'close', 'adj_close', 'high',\n",
       "       'low', 'Trade Impact_No Impact', 'Trade Impact_Positive Impact'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96ce167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5242, 14)\n",
      "(5242, 1)\n"
     ]
    }
   ],
   "source": [
    "#✅ 4.Assigning Variables (Independent/Dependent) : \n",
    "\n",
    "indep_X = dataset2.drop(['Trade Impact_Positive Impact'], axis=1)\n",
    "print(indep_X.shape)\n",
    "\n",
    "dep_Y = dataset2[['Trade Impact_Positive Impact']]\n",
    "print(dep_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ef8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#✅ 5.Creating Function(s) :\n",
    "\n",
    "def train_test_split_and_StandardScaler(indep_X,dep_Y):\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def RFE_Features_Classification(indep_X, dep_Y, n):\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "    \n",
    "    RFE_List = []\n",
    "\n",
    "    # Flatten y to a 1D array to avoid DataConversionWarning\n",
    "    dep_Y = dep_Y.values.ravel()\n",
    "\n",
    "    logistic_Regression = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
    "    #svc_Linear = SVC(kernel = 'linear', random_state = 0)\n",
    "    svc_Linear = LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
    "    decisionTree = DecisionTreeClassifier(criterion = 'gini',max_features = 'sqrt',splitter = 'best', random_state = 0)\n",
    "    randomForest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        \n",
    "    RFE_Model_List = [logistic_Regression, svc_Linear, decisionTree, randomForest]\n",
    "\n",
    "    for model in RFE_Model_List:\n",
    "        print(f\"\\nRunning RFE for: {model}\")\n",
    "        start = time.time()\n",
    "        \n",
    "        logistic_RFE = RFE(estimator = model, n_features_to_select = n)\n",
    "        logistic_RFE_Fit = logistic_RFE.fit(indep_X, dep_Y)\n",
    "        logistic_RFE_Feature = logistic_RFE.transform(indep_X)\n",
    "        RFE_List.append(logistic_RFE_Feature)\n",
    "        print(f\"Finished in {time.time() - start:.2f} seconds\")\n",
    "    return RFE_List\n",
    "\n",
    "def Confusion_Matrix(classifier, X_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    ConfusionMatrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import classification_report \n",
    "    ClassificationReport = classification_report(Y_test, y_pred)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    AccuracyScore=accuracy_score(Y_test, y_pred)         \n",
    "\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore \n",
    "\n",
    "def Logistic_Regression(X_train,Y_train,X_test):       \n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    #classifier = LogisticRegression(random_state = 0) \n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter= 10000)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore   \n",
    "\n",
    "def SVM_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def SVM_Non_Linear(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def Naive_Bayes(X_train,Y_train,X_test):       \n",
    "\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def KNN(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def DecisionTree(X_train,Y_train,X_test):\n",
    "\n",
    "    # Fitting K-NN to the Training set\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "def RandomForest(X_train,Y_train,X_test):\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Calling a Created Function - Confusion_Matrix(classifier,X_test) which returns - classifier, X_test, ConfusionMatrix, report, accuracy_score\n",
    "    classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Confusion_Matrix(classifier, X_test)\n",
    "    return classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore\n",
    "\n",
    "\n",
    "def RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                           accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest): \n",
    "\n",
    "    dataframe=pd.DataFrame(index=['Logistic Regression','SVM Linear','Decision Tree','Random Forest'],\n",
    "                           columns=['Logistic Regression','SVM Linear','SVM Non Linear','KNN','Naive Bayes',\n",
    "                                    'Decision Tree','Random Forest'])\n",
    "    \n",
    "    #Function - enumerate() acts as a Counter which Iterates index starting from 0 (by default) and their item(s) from the iterable\n",
    "    #Use enumerate() when We need both Position in the loop (number) and its value from the iterable (idex)\n",
    "    \n",
    "    for indexCount,indexValue in enumerate(dataframe.index):      \n",
    "        dataframe.loc[indexValue, 'Logistic Regression'] = accuracy_LogisticRegression[indexCount]       \n",
    "        dataframe.loc[indexValue, 'SVM Linear'] = accuracy_SVM_Linear[indexCount]\n",
    "        dataframe.loc[indexValue, 'SVM Non Linear'] = accuracy_SVM_NonLinear[indexCount]\n",
    "        dataframe.loc[indexValue, 'KNN'] = accuracy_KNN[indexCount]\n",
    "        dataframe.loc[indexValue, 'Naive Bayes'] = accuracy_NaiveBayes[indexCount]\n",
    "        dataframe.loc[indexValue, 'Decision Tree'] = accuracy_DecisionTree[indexCount]\n",
    "        dataframe.loc[indexValue, 'Random Forest'] = accuracy_RandomForest[indexCount]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44044d59-4a93-428b-b52a-cca4f13be0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b06307f7-9604-4e7d-a12a-f6cb4a10f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(indep_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3bf126-b30c-4b77-bf6a-5b695fe0fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<-------------------- Feature Count: 10 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.09 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.11 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.09 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 0.98 seconds\n",
      "\n",
      "<-------------------- Feature Count: 9 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.12 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.13 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.16 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.21 seconds\n",
      "\n",
      "<-------------------- Feature Count: 8 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.17 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.20 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.20 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.71 seconds\n",
      "\n",
      "<-------------------- Feature Count: 7 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.14 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.17 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.13 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.47 seconds\n",
      "\n",
      "<-------------------- Feature Count: 6 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.21 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.21 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.21 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.94 seconds\n",
      "\n",
      "<-------------------- Feature Count: 5 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.20 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.17 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.14 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.62 seconds\n",
      "\n",
      "<-------------------- Feature Count: 4 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.26 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.24 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.24 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.94 seconds\n",
      "\n",
      "<-------------------- Feature Count: 3 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.25 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.24 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.25 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.87 seconds\n",
      "\n",
      "<-------------------- Feature Count: 2 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.29 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.25 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.22 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.92 seconds\n",
      "\n",
      "<-------------------- Feature Count: 1 -------------------->\n",
      "\n",
      "Running RFE for: LogisticRegression(max_iter=1000)\n",
      "Finished in 0.25 seconds\n",
      "\n",
      "Running RFE for: LinearSVC(dual=False, max_iter=10000, random_state=0)\n",
      "Finished in 0.28 seconds\n",
      "\n",
      "Running RFE for: DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Finished in 0.19 seconds\n",
      "\n",
      "Running RFE for: RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "Finished in 1.92 seconds\n"
     ]
    }
   ],
   "source": [
    "# Enter the Number of Features\n",
    "No_Of_Features = 10\n",
    "Feature_List = []\n",
    "\n",
    "# Loop through and print each regressor name with its value\n",
    "for value in range(No_Of_Features, 0, -1):  # from 5 to 1 (inclusive)\n",
    "    print(f\"\\n<-------------------- Feature Count: {value} -------------------->\")\n",
    "\n",
    "    #✅ 6.Creating and Resetting accuracy lists for each feature count\n",
    "    accuracy_LogisticRegression = []\n",
    "    accuracy_SVM_Linear = []\n",
    "    accuracy_SVM_NonLinear = []\n",
    "    accuracy_KNN = []\n",
    "    accuracy_NaiveBayes = []\n",
    "    accuracy_DecisionTree = []\n",
    "    accuracy_RandomForest = []\n",
    "\n",
    "    #✅ 7.Calling a Created Function - RFE_Features_Classification(With Below Parameters): which returns - RFE_List\n",
    "    RFE_List = RFE_Features_Classification(X_scaled, dep_Y, value)\n",
    "\n",
    "    #✅ 8.Appending the Accuracy Score of All the Models in Created Empty List Through a For Loop \n",
    "    for X in RFE_List:\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split_and_StandardScaler(X, dep_Y)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Logistic_Regression(X_train, Y_train, X_test)\n",
    "        accuracy_LogisticRegression.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = SVM_Linear(X_train, Y_train, X_test)  \n",
    "        accuracy_SVM_Linear.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = SVM_Non_Linear(X_train, Y_train, X_test)  \n",
    "        accuracy_SVM_NonLinear.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = KNN(X_train, Y_train, X_test)  \n",
    "        accuracy_KNN.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = Naive_Bayes(X_train, Y_train, X_test)  \n",
    "        accuracy_NaiveBayes.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = DecisionTree(X_train, Y_train, X_test)  \n",
    "        accuracy_DecisionTree.append(AccuracyScore)\n",
    "        \n",
    "        classifier, X_test, Y_test, ConfusionMatrix, ClassificationReport, AccuracyScore = RandomForest(X_train, Y_train, X_test)  \n",
    "        accuracy_RandomForest.append(AccuracyScore)\n",
    "\n",
    "    #✅ 9.Calling a Created Function - RFE_Classification(With Below Parameters): which returns - dataframe    \n",
    "    result = RFE_Classification(accuracy_LogisticRegression, accuracy_SVM_Linear, accuracy_SVM_NonLinear, \n",
    "                               accuracy_KNN, accuracy_NaiveBayes, accuracy_DecisionTree, accuracy_RandomForest)\n",
    "\n",
    "    # Append a dictionary with feature count and result\n",
    "    Feature_List.append({\n",
    "        \"Feature_Count\": value,  # Number of features used\n",
    "        \"Result\": result         # DataFrame of accuracy scores from multiple classifiers\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d0e4d2-1c75-45d7-a082-1b62868a2f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM Linear</th>\n",
       "      <th>SVM Non Linear</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Feature_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.427155</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.636156</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.636156</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.617849</td>\n",
       "      <td>0.987796</td>\n",
       "      <td>0.990084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.638444</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.636156</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.995423</td>\n",
       "      <td>0.382151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.998474</td>\n",
       "      <td>0.382914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.639969</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.993135</td>\n",
       "      <td>0.382151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.995423</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.998474</td>\n",
       "      <td>0.429443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.994661</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.430206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.990084</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.630053</td>\n",
       "      <td>0.975591</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996186</td>\n",
       "      <td>0.428680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.634630</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.630053</td>\n",
       "      <td>0.978642</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.897788</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.993898</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.630053</td>\n",
       "      <td>0.915332</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.895500</td>\n",
       "      <td>0.386728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.929062</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.641495</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.929062</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.630816</td>\n",
       "      <td>0.918383</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.630816</td>\n",
       "      <td>0.918383</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.636918</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.909230</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.630816</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.635393</td>\n",
       "      <td>0.630816</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.906178</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.639207</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>0.906941</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Logistic Regression  SVM Linear  SVM Non Linear       KNN  Naive Bayes  \\\n",
       "36             0.617849    0.617849        0.617849  0.617849     0.427155   \n",
       "37             0.636156    0.633105        0.633867  1.000000     0.617849   \n",
       "38             0.636156    0.633105        0.633867  1.000000     0.617849   \n",
       "39             0.635393    0.633105        0.633105  0.996186     0.617849   \n",
       "32             0.638444    0.633105        0.632342  1.000000     0.428680   \n",
       "33             0.636156    0.633105        0.631579  0.996949     0.385202   \n",
       "34             0.636918    0.633105        0.632342  0.995423     0.382151   \n",
       "35             0.639207    0.633867        0.633105  0.998474     0.382914   \n",
       "31             0.639969    0.634630        0.632342  0.993135     0.382151   \n",
       "30             0.637681    0.633867        0.632342  0.996949     0.384439   \n",
       "29             0.637681    0.633867        0.632342  0.995423     0.384439   \n",
       "28             0.640732    0.633867        0.632342  0.998474     0.429443   \n",
       "27             0.640732    0.634630        0.632342  0.994661     0.384439   \n",
       "26             0.636918    0.633105        0.631579  0.978642     0.385202   \n",
       "25             0.640732    0.634630        0.632342  0.996186     0.384439   \n",
       "24             0.640732    0.633867        0.632342  0.996186     0.430206   \n",
       "23             0.640732    0.634630        0.632342  0.990084     0.384439   \n",
       "22             0.636918    0.633105        0.630053  0.975591     0.385202   \n",
       "21             0.640732    0.634630        0.632342  0.996949     0.385202   \n",
       "20             0.641495    0.634630        0.632342  0.996186     0.428680   \n",
       "19             0.639207    0.633867        0.631579  0.978642     0.385202   \n",
       "18             0.636918    0.633105        0.629291  0.971014     0.385202   \n",
       "17             0.641495    0.634630        0.631579  0.996949     0.431732   \n",
       "16             0.641495    0.634630        0.631579  0.996949     0.431732   \n",
       "15             0.639207    0.633867        0.630053  0.978642     0.385202   \n",
       "14             0.636918    0.633105        0.628528  0.897788     0.385965   \n",
       "13             0.641495    0.635393        0.632342  0.993898     0.431732   \n",
       "12             0.641495    0.635393        0.632342  0.993898     0.431732   \n",
       "11             0.639207    0.633867        0.630053  0.915332     0.385965   \n",
       "10             0.636918    0.633105        0.628528  0.895500     0.386728   \n",
       "9              0.641495    0.635393        0.632342  0.929062     0.431732   \n",
       "8              0.641495    0.635393        0.632342  0.929062     0.431732   \n",
       "4              0.640732    0.635393        0.630816  0.918383     0.431732   \n",
       "5              0.640732    0.635393        0.630816  0.918383     0.431732   \n",
       "6              0.636918    0.633105        0.628528  0.894737     0.385202   \n",
       "7              0.639207    0.633867        0.629291  0.909230     0.385965   \n",
       "0              0.640732    0.635393        0.630816  0.913043     0.431732   \n",
       "1              0.640732    0.635393        0.630816  0.913043     0.431732   \n",
       "2              0.639207    0.633867        0.628528  0.906178     0.385202   \n",
       "3              0.639207    0.633867        0.628528  0.906941     0.385202   \n",
       "\n",
       "    Decision Tree  Random Forest  Feature_Count  \n",
       "36       0.617849       0.617849              1  \n",
       "37       1.000000       1.000000              1  \n",
       "38       1.000000       1.000000              1  \n",
       "39       0.987796       0.990084              1  \n",
       "32       1.000000       1.000000              2  \n",
       "33       1.000000       1.000000              2  \n",
       "34       1.000000       1.000000              2  \n",
       "35       1.000000       1.000000              2  \n",
       "31       1.000000       0.999237              3  \n",
       "30       1.000000       1.000000              3  \n",
       "29       1.000000       1.000000              3  \n",
       "28       1.000000       1.000000              3  \n",
       "27       1.000000       1.000000              4  \n",
       "26       1.000000       1.000000              4  \n",
       "25       1.000000       1.000000              4  \n",
       "24       1.000000       1.000000              4  \n",
       "23       1.000000       1.000000              5  \n",
       "22       1.000000       1.000000              5  \n",
       "21       1.000000       1.000000              5  \n",
       "20       1.000000       1.000000              5  \n",
       "19       1.000000       1.000000              6  \n",
       "18       1.000000       1.000000              6  \n",
       "17       1.000000       1.000000              6  \n",
       "16       1.000000       1.000000              6  \n",
       "15       1.000000       1.000000              7  \n",
       "14       1.000000       1.000000              7  \n",
       "13       1.000000       1.000000              7  \n",
       "12       1.000000       1.000000              7  \n",
       "11       1.000000       0.999237              8  \n",
       "10       1.000000       0.999237              8  \n",
       "9        1.000000       1.000000              8  \n",
       "8        1.000000       1.000000              8  \n",
       "4        1.000000       1.000000              9  \n",
       "5        1.000000       1.000000              9  \n",
       "6        1.000000       1.000000              9  \n",
       "7        1.000000       1.000000              9  \n",
       "0        1.000000       0.999237             10  \n",
       "1        1.000000       0.999237             10  \n",
       "2        1.000000       1.000000             10  \n",
       "3        1.000000       1.000000             10  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all results into one DataFrame\n",
    "combined_df = pd.concat([item[\"Result\"].assign(Feature_Count = item[\"Feature_Count\"]) for item in Feature_List], axis=0)\n",
    "\n",
    "# Optional: reset index for cleanliness\n",
    "combined_df = combined_df.reset_index()\n",
    "\n",
    "# Convert all string columns to int (if safe)\n",
    "combined_df = combined_df.apply(pd.to_numeric, errors='coerce')\n",
    "combined_df = combined_df.drop([\"index\"], axis=1)\n",
    "\n",
    "# Sort by Feature_Count in ascending order\n",
    "sorted_df = combined_df.sort_values(by='Feature_Count', ascending=True)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdb7f0bd-8ce1-4304-9c2a-21b860be4205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVM Linear</th>\n",
       "      <th>SVM Non Linear</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Feature_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640732</td>\n",
       "      <td>0.633105</td>\n",
       "      <td>0.632342</td>\n",
       "      <td>0.996949</td>\n",
       "      <td>0.385202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Logistic Regression  SVM Linear  SVM Non Linear       KNN  Naive Bayes  \\\n",
       "0             0.640732    0.633105        0.632342  0.996949     0.385202   \n",
       "1                  NaN         NaN             NaN       NaN     0.431732   \n",
       "2                  NaN         NaN             NaN       NaN          NaN   \n",
       "3                  NaN         NaN             NaN       NaN          NaN   \n",
       "4                  NaN         NaN             NaN       NaN          NaN   \n",
       "5                  NaN         NaN             NaN       NaN          NaN   \n",
       "6                  NaN         NaN             NaN       NaN          NaN   \n",
       "7                  NaN         NaN             NaN       NaN          NaN   \n",
       "8                  NaN         NaN             NaN       NaN          NaN   \n",
       "9                  NaN         NaN             NaN       NaN          NaN   \n",
       "\n",
       "   Decision Tree  Random Forest  Feature_Count  \n",
       "0            1.0            1.0              1  \n",
       "1            NaN            NaN              2  \n",
       "2            NaN            NaN              3  \n",
       "3            NaN            NaN              4  \n",
       "4            NaN            NaN              5  \n",
       "5            NaN            NaN              6  \n",
       "6            NaN            NaN              7  \n",
       "7            NaN            NaN              8  \n",
       "8            NaN            NaN              9  \n",
       "9            NaN            NaN             10  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_table = sorted_df.mode()\n",
    "mode_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc7ac3e7-8960-44cd-9571-3cbcc6156a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Logistic Regression    0.640732\n",
       "SVM Linear             0.633105\n",
       "SVM Non Linear         0.632342\n",
       "KNN                    0.996949\n",
       "Naive Bayes            0.431732\n",
       "Decision Tree          1.000000\n",
       "Random Forest          1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_max = mode_table.max().drop([\"Feature_Count\"], axis=0)\n",
    "mode_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30019b83-c59b-4cba-9f47-2b4b9ef7c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classifiers with Highest Repeatation and Maximum Value(s):\n",
      "Decision Tree    1.0\n",
      "Random Forest    1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the maximum value\n",
    "mode_max_final = mode_max.max()\n",
    "\n",
    "# Get all Classifiers with the maximum value\n",
    "mode_max_final_items = mode_max[mode_max == mode_max_final]\n",
    "\n",
    "# Display names along with values\n",
    "print(f\"Final Classifiers with Highest Repeatation and Maximum Value(s):\\n{mode_max_final_items}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
