{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee14f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Formatting :\n",
    "    \n",
    "    # Creating a Dynamic Function - highlight_max_min(with Parameter) to Highlight Maximum and Minimum Value of any Dataframe\n",
    "\n",
    "    def highlight_max_min(self, dataframe):\n",
    "        \"\"\"\n",
    "        Highlights the maximum and minimum values in a DataFrame dynamically.\n",
    "\n",
    "        Parameters:\n",
    "            dataframe (pd.DataFrame): The DataFrame to be styled.\n",
    "\n",
    "        Returns:\n",
    "            pd.io.formats.style.Styler: Styled DataFrame with applied highlights.\n",
    "        \"\"\"\n",
    "        styles = []  # Initialize a list to store styles for each cell\n",
    "\n",
    "        # Iterate over the DataFrame rows and columns dynamically\n",
    "        for row in dataframe.index:\n",
    "            row_styles = []  # Temporary list to store styles for the current row\n",
    "            for column in dataframe.columns:\n",
    "                value = dataframe.loc[row, column]  # Retrieve the cell value dynamically\n",
    "\n",
    "                # Check if the value is the maximum or minimum in the entire DataFrame\n",
    "                if value == dataframe.max().max():  # Global maximum value\n",
    "                    row_styles.append('background-color: lightgreen')  # Highlight in green\n",
    "                elif value == dataframe.min().min():  # Global minimum value\n",
    "                    row_styles.append('background-color: red')  # Highlight in red\n",
    "                else:\n",
    "                    row_styles.append('background-color: white')  # Default background for other cells\n",
    "\n",
    "            # Append the styles for the current row\n",
    "            styles.append(row_styles)\n",
    "\n",
    "        # Convert the styles into a DataFrame for styling compatibility\n",
    "        def apply_styles_to_cells(df):\n",
    "            return pd.DataFrame(styles, index=df.index, columns=df.columns)\n",
    "\n",
    "        # Apply the styles dynamically to the given DataFrame\n",
    "        return dataframe.style.apply(apply_styles_to_cells, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5181e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a Function - ANOVA_Paired_TTest_Dependent_Sample (With 4 Parameters as Input) \n",
    "to Automate the ANAVO Analysis for Paired T-Test (Dependent Sample)\n",
    "\"\"\"\n",
    "\n",
    "def ANOVA_Paired_TTest_Dependent_Sample(Categorical_Column_Name, Selection_In_Categorical_Column, Numerical_Group_01, Numerical_Group_02):\n",
    "    \"\"\"\n",
    "    Performs a Paired T-Test (Dependent Sample) to check for significant differences\n",
    "    between two conditions for the same Numerical_Group.\n",
    "    \n",
    "    Parameters:\n",
    "        Categorical_Column_Name (str): Column name for the Numerical_Group (categorical).\n",
    "        Selection_In_Categorical_Column (str): Specific Numerical_Group selection (\"M\" Or \"F\").\n",
    "        Numerical_Group_01 (str): First numerical column to compare.\n",
    "        Numerical_Group_02 (str): Second numerical column to compare.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the result of the hypothesis test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importing the required function from the scipy library\n",
    "    from scipy.stats import ttest_rel\n",
    "    \n",
    "    # Querying the dataset for the specified Numerical_Group and conditions\n",
    "    Numerical_Group_01_Input = dataset[dataset[Categorical_Column_Name] == Selection_In_Categorical_Column][Numerical_Group_01]\n",
    "    Numerical_Group_02_Input = dataset[dataset[Categorical_Column_Name] == Selection_In_Categorical_Column][Numerical_Group_02]\n",
    "\n",
    "    # Calculating the Paired T-Test\n",
    "    statistic, pvalue = ttest_rel(Numerical_Group_01_Input, Numerical_Group_02_Input)\n",
    "\n",
    "    # Converting p-value to percentage\n",
    "    pvalue_percentage = pvalue * 100\n",
    "\n",
    "    # Displaying the results\n",
    "    print(f\"Statistic: {statistic}\")\n",
    "    print(f\"p-value: {pvalue}\")\n",
    "    \n",
    "    standard_pValue = 0.05\n",
    "    \n",
    "    # Hypothesis Testing\n",
    "    if pvalue < standard_pValue :  # Compare the raw p-value (not percentage)\n",
    "        print(\"\\nResult:\")\n",
    "        print(f\"p-value as a percentage: {pvalue_percentage:.2f}%\")\n",
    "        print(\"H0 / Null Hypothesis: There is no significant difference.\")\n",
    "        print(\"H1 / Alternate Hypothesis: There is a significant difference.\")\n",
    "        print(\"\\nConclusion:\", \"\\nRejected - H0 / Null Hypothesis since p-value < 0.05%.\")\n",
    "        print(\"Accepted - H1 / Alternate Hypothesis.\")\n",
    "    else:\n",
    "        print(\"\\nResult:\")\n",
    "        print(f\"p-value as a percentage: {pvalue_percentage:.2f}%\")\n",
    "        print(\"H1 / Alternate Hypothesis: There is a significant difference.\")\n",
    "        print(\"H0 / Null Hypothesis: There is no significant difference.\")\n",
    "        print(\"\\nConclusion:\", \"\\nAccepted - H0 / Null Hypothesis since p-value >= 0.05%.\")\n",
    "        print(\"Rejected - H1 / Alternate Hypothesis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b43514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating a Function - ANOVA_Unpaired_TTest_Two_Independent_Sample (With 4 Parameters as Input) \n",
    "to Automate the ANAVO Analysis for Paired T-Test (Dependent Sample)\n",
    "\"\"\"\n",
    "\n",
    "def ANOVA_Unpaired_TTest_Two_Independent_Sample(\n",
    "    Categorical_Column_01, Selection_In_Categorical_Column_01, \n",
    "    Categorical_Column_02, Selection_In_Categorical_Column_02,\n",
    "    Numerical_Condition_01):\n",
    "    \"\"\"\n",
    "    Performs a Unpaired T-Test (Two_Independent Sample) to check for significant differences\n",
    "    between two conditions for the same Numerical_Group.\n",
    "    \n",
    "    Parameters:\n",
    "        Categorical_Column_01 (str): First categorical column to filter (e.g., 'degree_t').\n",
    "        Selection_In_Categorical_Column_01 (str): Value to match in the first categorical column (e.g., 'Sci&Tech').\n",
    "        Categorical_Column_02 (str): Second categorical column to filter (e.g., 'specialisation').\n",
    "        Selection_In_Categorical_Column_02 (str): Value to match in the second categorical column (e.g., 'Mkt&HR').\n",
    "        Numerical_Column (str): The numerical column to test (e.g., 'salary').\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the result of the hypothesis test.\n",
    "    \"\"\"\n",
    "    \n",
    "    # importing a Function - ttest_ind from Module - stats of Library - scipy \n",
    "    from scipy.stats import ttest_ind\n",
    "    \n",
    "    # Querying the dataset for Two Different Groups and One Numerical condition\n",
    "    Categorical_Group_01_Input = dataset[(dataset[Categorical_Column_01] == Selection_In_Categorical_Column_01) &\n",
    "    (dataset[Categorical_Column_02] == Selection_In_Categorical_Column_02)][Numerical_Condition_01]\n",
    "    \n",
    "    # Querying the dataset Otherthan Two Different Groups and One Numerical condition\n",
    "    Categorical_Group_02_Input = dataset[\n",
    "        ~(dataset[Categorical_Column_01] == Selection_In_Categorical_Column_01) &\n",
    "    (dataset[Categorical_Column_02] == Selection_In_Categorical_Column_02)] [Numerical_Condition_01]\n",
    "    \n",
    "    # Calculating the Paired T-Test\n",
    "    statistic, pvalue = ttest_ind(Categorical_Group_01_Input, Categorical_Group_02_Input)\n",
    "\n",
    "    # Converting p-value to percentage\n",
    "    pvalue_percentage = pvalue * 100\n",
    "\n",
    "    # Displaying the results\n",
    "    print(f\"Statistic: {statistic}\")\n",
    "    print(f\"p-value: {pvalue}\")\n",
    "    \n",
    "    standard_pValue = 0.05\n",
    "    \n",
    "    # Hypothesis Testing\n",
    "    if pvalue < standard_pValue :  # Compare the raw p-value (not percentage)\n",
    "        print(\"\\nResult:\")\n",
    "        print(f\"p-value as a percentage: {pvalue_percentage:.2f}%\")\n",
    "        print(\"H0 / Null Hypothesis: There is no significant difference.\")\n",
    "        print(\"H1 / Alternate Hypothesis: There is a significant difference.\")\n",
    "        print(\"\\nConclusion:\", \"\\nRejected - H0 / Null Hypothesis since p-value < 0.05%.\")\n",
    "        print(\"Accepted - H1 / Alternate Hypothesis.\")\n",
    "    else:\n",
    "        print(\"\\nResult:\")\n",
    "        print(f\"p-value as a percentage: {pvalue_percentage:.2f}%\")\n",
    "        print(\"H0 / Null Hypothesis: There is no significant difference.\")\n",
    "        print(\"H1 / Alternate Hypothesis: There is a significant difference.\")\n",
    "        print(\"\\nConclusion:\", \"\\nAccepted - H0 / Null Hypothesis since p-value >= 0.05%.\")\n",
    "        print(\"Rejected - H1 / Alternate Hypothesis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
